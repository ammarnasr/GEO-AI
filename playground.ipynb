{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import folium\n",
    "import joblib\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import geopandas as gpd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "\n",
    "bands_all = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08','B8A', 'B09', 'B10', 'B11', 'B12']\n",
    "bands_fcover = ['FCOVER']\n",
    "\n",
    "def get_gdf_deviding_vals(gdf):\n",
    "    lats = gdf['Lat'].values\n",
    "    lons = gdf['Lon'].values\n",
    "    total_bounds = gdf.total_bounds\n",
    "    lats_min  = total_bounds[1]\n",
    "    lats_max  = total_bounds[3]\n",
    "    lats_deviding_val = lats_min + (lats_max-lats_min)/2\n",
    "    lons_min  = total_bounds[0]\n",
    "    lons_max  = total_bounds[2]\n",
    "    lons_deviding_val = lons_min + (lons_max-lons_min)/2\n",
    "    d = {\n",
    "        'lats_min': lats_min,\n",
    "        'lats_max': lats_max,\n",
    "        'lats_deviding_val': lats_deviding_val,\n",
    "        'lons_min': lons_min,\n",
    "        'lons_max': lons_max,\n",
    "        'lons_deviding_val': lons_deviding_val\n",
    "    }\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_north_west_gdf(gdf):\n",
    "    d = get_gdf_deviding_vals(gdf)\n",
    "    lats_deviding_val = d['lats_deviding_val']\n",
    "    lons_deviding_val = d['lons_deviding_val']\n",
    "    gdf = gdf[gdf['Lat'] > lats_deviding_val]\n",
    "    gdf = gdf[gdf['Lon'] < lons_deviding_val]\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def get_south_east_gdf(gdf):\n",
    "    d = get_gdf_deviding_vals(gdf)\n",
    "    lats_deviding_val = d['lats_deviding_val']\n",
    "    lons_deviding_val = d['lons_deviding_val']\n",
    "    gdf = gdf[gdf['Lat'] < lats_deviding_val]\n",
    "    gdf = gdf[gdf['Lon'] > lons_deviding_val]\n",
    "    return gdf\n",
    "def get_north_east_gdf(gdf):\n",
    "    d = get_gdf_deviding_vals(gdf)\n",
    "    lats_deviding_val = d['lats_deviding_val']\n",
    "    lons_deviding_val = d['lons_deviding_val']\n",
    "    gdf = gdf[gdf['Lat'] > lats_deviding_val]\n",
    "    gdf = gdf[gdf['Lon'] > lons_deviding_val]\n",
    "    return gdf\n",
    "def get_south_west_gdf(gdf):\n",
    "    d = get_gdf_deviding_vals(gdf)\n",
    "    lats_deviding_val = d['lats_deviding_val']\n",
    "    lons_deviding_val = d['lons_deviding_val']\n",
    "    gdf = gdf[gdf['Lat'] < lats_deviding_val]\n",
    "    gdf = gdf[gdf['Lon'] < lons_deviding_val]\n",
    "    return gdf\n",
    "def donwload_images_for_all_scriprs(gdf, date, country):\n",
    "    evalscript_clp = 'CLP'\n",
    "    evalscript_true_color = 'TRUECOLOR'\n",
    "    evalscript_all = 'ALL'\n",
    "    evalscript_fcover = 'FCOVER'\n",
    "    clp_image, clp_dir = utils.download_gdf_image_from_sentinelhub(gdf, date, evalscript_clp, country)\n",
    "    true_color_image, true_color_dir = utils.download_gdf_image_from_sentinelhub(gdf, date, evalscript_true_color, country)\n",
    "    all_image, all_dir = utils.download_gdf_image_from_sentinelhub(gdf, date, evalscript_all, country)\n",
    "    fcover_image, fcover_dir = utils.download_gdf_image_from_sentinelhub(gdf, date, evalscript_fcover, country)\n",
    "    d = {\n",
    "        'clp_image': clp_image,\n",
    "        'clp_dir': clp_dir,\n",
    "        'true_color_image': true_color_image,\n",
    "        'true_color_dir': true_color_dir,\n",
    "        'all_image': all_image,\n",
    "        'all_dir': all_dir,\n",
    "        'fcover_image': fcover_image,\n",
    "        'fcover_dir': fcover_dir\n",
    "    }\n",
    "    return d\n",
    "def rastrio_img(df, index):\n",
    "    row = df.iloc[index]\n",
    "    img_path = utils.get_image_path_from_row(row)\n",
    "    img = utils.read_image_with_rasterio(img_path)\n",
    "    return img\n",
    "def get_lats_lons_from_raster(src):\n",
    "    band1 = src.read(1)\n",
    "    height = band1.shape[0]\n",
    "    width = band1.shape[1]\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rasterio.transform.xy(src.transform, rows, cols)\n",
    "    lons= np.array(xs)\n",
    "    lats = np.array(ys)\n",
    "    return lats, lons\n",
    "def gdf_from_raster(src, bands_names=None):\n",
    "    lats, lons = get_lats_lons_from_raster(src)\n",
    "    img_array = np.array(src.read())\n",
    "    if bands_names is None:\n",
    "        bands_names = [f'B{i}' for i in range(src.count)]\n",
    "    lats = lats.flatten()\n",
    "    lons = lons.flatten()\n",
    "    img_array = img_array.reshape((img_array.shape[0], img_array.shape[1]*img_array.shape[2]))\n",
    "    df = pd.DataFrame(img_array.T, columns=bands_names)\n",
    "    df['Lat'] = lats\n",
    "    df['Lon'] = lons\n",
    "    geom = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        p = utils.shapely_point(lats[i], lons[i]) \n",
    "        geom.append(p)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geom)\n",
    "    gdf.crs = src.crs\n",
    "    gdf = gdf.to_crs('EPSG:4326')\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "    return gdf\n",
    "def get_gdf_from_row(df, row, bands_names=None):\n",
    "    src = rastrio_img(df, row)\n",
    "    gdf = gdf_from_raster(src, bands_names)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def get_processed_masked_src_gdf(gdf, masking_dict):\n",
    "    eq_points_indicies = masking_dict['eq_points_indicies']\n",
    "    eq_points_targets = masking_dict['eq_points_targets']\n",
    "    gdf = gdf.iloc[eq_points_indicies]\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "    gdf['Target'] = eq_points_targets\n",
    "    return gdf\n",
    "\n",
    "def small_df(df, s=1000):\n",
    "    df_small = df.sample(s, random_state=42)\n",
    "    df_small = df_small.reset_index(drop=True)\n",
    "    return df_small\n",
    "\n",
    "def explore_gdf(gdf, m, color='green', radius=1, name=None):\n",
    "    if len(gdf) > 0:\n",
    "        gdf.explore(m=m,  marker_kwds={'radius': radius, 'color': color, 'fill': True, 'fill_color': color}, name=name)\n",
    "\n",
    "def get_locations_and_map(data, country):\n",
    "    gdf = data[data['Country'] == country]\n",
    "    gdf_centroid = utils.gdf_center(gdf)\n",
    "    gdf_north_west = get_north_west_gdf(gdf)\n",
    "    gdf_south_east = get_south_east_gdf(gdf)\n",
    "    gdf_north_east = get_north_east_gdf(gdf)\n",
    "    gdf_south_west = get_south_west_gdf(gdf)\n",
    "\n",
    "    m = folium.Map(location=[gdf_centroid.y , gdf_centroid.x], zoom_start=10)\n",
    "    m = utils.add_esri_satellite_layer(m)\n",
    "    m = utils.gdf_square_map(gdf, m=m)\n",
    "    m = utils.gdf_square_map(gdf_north_west, m=m)\n",
    "    m = utils.gdf_square_map(gdf_south_east, m=m)\n",
    "    m = utils.gdf_square_map(gdf_north_east, m=m)\n",
    "    m = utils.gdf_square_map(gdf_south_west, m=m)\n",
    "\n",
    "    explore_gdf(gdf_north_west, m=m, color='black', radius=5, name='north_west')\n",
    "    explore_gdf(gdf_south_east, m=m, color='white', radius=5, name='south_east')\n",
    "    explore_gdf(gdf_north_east, m=m, color='red', radius=5, name='north_east')\n",
    "    explore_gdf(gdf_south_west, m=m, color='blue', radius=5, name='south_west')\n",
    "    explore_gdf(gdf, m=m, color='green', radius=1, name='all')\n",
    "    folium.LayerControl().add_to(m)\n",
    "    return gdf, m, gdf_north_west, gdf_south_east, gdf_north_east, gdf_south_west\n",
    "\n",
    "\n",
    "def filter_date_by_month(dates, month):\n",
    "    return [date for date in dates if date.split('-')[1] == month]\n",
    "def filter_date_by_year(dates, year):\n",
    "    return [date for date in dates if date.split('-')[0] == year]\n",
    "\n",
    "def process_paths_df(paths_df, evalscript):\n",
    "    current_image_paths_df = paths_df[paths_df['evalscript'] == evalscript]\n",
    "    current_image_paths_df = current_image_paths_df.reset_index(drop=True)\n",
    "    src_gdfs_evalscript = []\n",
    "    if evalscript == 'ALL':\n",
    "        bands = bands_all\n",
    "    elif evalscript == 'FCOVER':\n",
    "        bands = bands_fcover\n",
    "    for i in tqdm(range(len(current_image_paths_df))):\n",
    "        current_date = current_image_paths_df.iloc[i]['date']\n",
    "        src_gdf = get_gdf_from_row(current_image_paths_df, i, bands_names=bands)\n",
    "        new_names_dict = {}\n",
    "        for col in src_gdf.columns:\n",
    "            if col in bands:\n",
    "                new_names_dict[col] = f'{col}_{current_date}'\n",
    "            else:\n",
    "                new_names_dict[col] = col\n",
    "        src_gdf = src_gdf.rename(columns=new_names_dict)\n",
    "        src_gdfs_evalscript.append(src_gdf)\n",
    "    return src_gdfs_evalscript\n",
    "\n",
    "def merege_src_gdf_columns_by_date(src_gdfs):\n",
    "    src_gdfs_data_clos = []\n",
    "    for src_gdf in src_gdfs:\n",
    "        src_gdf = src_gdf.drop(columns=['Lat', 'Lon', 'geometry'])\n",
    "        src_gdfs_data_clos.append(src_gdf)\n",
    "    src_gdfs = pd.concat(src_gdfs_data_clos, axis=1)\n",
    "    src_gdfs = src_gdfs.reset_index(drop=True)\n",
    "    return src_gdfs\n",
    "\n",
    "\n",
    "\n",
    "def get_processed_src_gdf(paths_df, dates = None):\n",
    "    if dates is not None:\n",
    "        paths_df = paths_df[paths_df['date'].isin(dates)]\n",
    "        paths_df = paths_df.reset_index(drop=True)\n",
    "    \n",
    "    src_gdfs_ALL_evalscript = process_paths_df(paths_df, 'ALL')\n",
    "    src_gdfs_FCOVER_evalscript = process_paths_df(paths_df, 'FCOVER')\n",
    "    lat_col = src_gdfs_ALL_evalscript[0]['Lat']\n",
    "    lon_col = src_gdfs_ALL_evalscript[0]['Lon']\n",
    "    geom_col = src_gdfs_ALL_evalscript[0]['geometry']\n",
    "    src_gdfs_ALL_evalscript_mereged = merege_src_gdf_columns_by_date(src_gdfs_ALL_evalscript)\n",
    "    src_gdfs_FCOVER_evalscript_mereged = merege_src_gdf_columns_by_date(src_gdfs_FCOVER_evalscript)\n",
    "    src_gdf= pd.concat([src_gdfs_ALL_evalscript_mereged, src_gdfs_FCOVER_evalscript_mereged], axis=1)\n",
    "    src_gdf['Location'] = paths_df['location'].values[0]\n",
    "    src_gdf['Lat'] = lat_col\n",
    "    src_gdf['Lon'] = lon_col\n",
    "    src_gdf['geometry'] = geom_col\n",
    "    src_gdf = gpd.GeoDataFrame(src_gdf, geometry='geometry')\n",
    "    src_gdf.crs = 'EPSG:4326'\n",
    "    src_gdf = src_gdf.reset_index(drop=True)\n",
    "    return src_gdf\n",
    "\n",
    "def get_processed_src_gdf_fcover(paths_df):\n",
    "    src_gdf = process_paths_df(paths_df, 'FCOVER')\n",
    "    src_gdf = src_gdf[0]\n",
    "    src_gdf['Location'] = paths_df['location'].values[0]\n",
    "    src_gdf = gpd.GeoDataFrame(src_gdf, geometry='geometry')\n",
    "    src_gdf.crs = 'EPSG:4326'\n",
    "    src_gdf = src_gdf.reset_index(drop=True)\n",
    "    return src_gdf\n",
    "\n",
    "def get_masking_dict_for_src_from_target(src_geom, target_gdf, dict_path):\n",
    "    if os.path.exists(dict_path):\n",
    "        calculated_dict = joblib.load(dict_path)\n",
    "    else:\n",
    "        target_geom = target_gdf.geometry.values\n",
    "        target_gdf_cols = target_gdf.columns\n",
    "        if 'Target' in target_gdf_cols:\n",
    "            target_labels = target_gdf.Target.values\n",
    "        else:\n",
    "            target_labels = [-1 for i in range(len(target_geom))]\n",
    "        eq_points_indicies = []\n",
    "        eq_points_targets = []\n",
    "        j = 0\n",
    "        for target_point in tqdm(target_geom):\n",
    "            t = target_labels[j]\n",
    "            j+=1\n",
    "            i = 0\n",
    "            for src_point in src_geom:\n",
    "                if src_point.equals_exact(target_point, 1e-4):\n",
    "                    eq_points_indicies.append(i)\n",
    "                    eq_points_targets.append(t)\n",
    "                i+=1\n",
    "        calculated_dict = {\n",
    "            'eq_points_indicies': eq_points_indicies,\n",
    "            'eq_points_targets': eq_points_targets,\n",
    "        }\n",
    "        joblib.dump(calculated_dict, dict_path)\n",
    "    return calculated_dict\n",
    "\n",
    "\n",
    "def decrease_gdf_height_by_removing_max_and_min_lats(gdf, n=1):\n",
    "    if n > 0:\n",
    "        gdf = gdf.reset_index(drop=True)\n",
    "        lats = gdf['Lat'].values\n",
    "        sorted_lats_indicies = np.argsort(lats)\n",
    "        n_max = sorted_lats_indicies[-n:]\n",
    "        n_min = sorted_lats_indicies[:n]\n",
    "        print(f'Max indicies: {n_max}, Max lats: {lats[n_max]}')\n",
    "        print(f'Min indicies: {n_min}, Min lats: {lats[n_min]}')\n",
    "        #drop rows with max and min lats indicies\n",
    "        gdf = gdf.drop(n_max)\n",
    "        gdf = gdf.drop(n_min)\n",
    "        gdf = gdf.reset_index(drop=True)\n",
    "    return gdf\n",
    "\n",
    "def decrease_gdf_width_by_removing_max_and_min_lons(gdf, m=1):\n",
    "    if m > 0:\n",
    "        gdf = gdf.reset_index(drop=True)\n",
    "        lons = gdf['Lon'].values\n",
    "        sorted_lons_indicies = np.argsort(lons)\n",
    "        m_max = sorted_lons_indicies[-m:]\n",
    "        m_min = sorted_lons_indicies[:m]\n",
    "        print(f'Max indicies: {m_max}, Max lons: {lons[m_max]}')\n",
    "        print(f'Min indicies: {m_min}, Min lons: {lons[m_min]}')\n",
    "        #drop rows with max and min lons indicies\n",
    "        gdf = gdf.drop(m_max)\n",
    "        gdf = gdf.drop(m_min)\n",
    "        gdf = gdf.reset_index(drop=True)\n",
    "    return gdf\n",
    "\n",
    "def decrease_gdf_height_and_width(gdf, n, m):\n",
    "    gdf = decrease_gdf_height_by_removing_max_and_min_lats(gdf, n)\n",
    "    gdf = decrease_gdf_width_by_removing_max_and_min_lons(gdf, m)\n",
    "    return gdf\n",
    "\n",
    "def reszie_quarter_gdfs(country_quarter_split_gdf, country_quarter_split_gdf_name):\n",
    "    if country_quarter_split_gdf_name == 'Iran_North_West_test':\n",
    "        n = 1\n",
    "        m = 0\n",
    "    elif country_quarter_split_gdf_name == 'Iran_South_East_test':\n",
    "        n = 8\n",
    "        m = 0\n",
    "    elif country_quarter_split_gdf_name == 'Iran_North_East_test':\n",
    "        n = 5\n",
    "        m = 0\n",
    "    elif country_quarter_split_gdf_name == 'Iran_South_West_test':\n",
    "        n = 3\n",
    "        m = 0\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_North_West_test':\n",
    "        n = 4\n",
    "        m = 5\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_South_East_test':\n",
    "        n = 2\n",
    "        m = 1\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_North_East_test':\n",
    "        n = 0\n",
    "        m = 1\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_South_West_test':\n",
    "        n = 4\n",
    "        m = 1\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_North_West_train':\n",
    "        n = 0\n",
    "        m = 1\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_South_East_train':\n",
    "        n = 0\n",
    "        m = 1\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_North_East_train':\n",
    "        n = 0\n",
    "        m = 3\n",
    "    elif country_quarter_split_gdf_name == 'Sudan_South_West_train':\n",
    "        n = 1\n",
    "        m = 0\n",
    "    else:\n",
    "        n = 0\n",
    "        m = 0\n",
    "    country_quarter_split_gdf = decrease_gdf_height_and_width(country_quarter_split_gdf, n, m)\n",
    "    return country_quarter_split_gdf\n",
    "        \n",
    "\n",
    "def creat_masking_dict(target_gdf, country, direction, train_or_test, target_location, part2=False):\n",
    "    processed_gdf_path = f'{country}_{direction}_{train_or_test}_processed_gdf.joblib'\n",
    "    if os.path.exists(processed_gdf_path):\n",
    "        print(f'processed_gdf_path: {processed_gdf_path} exists')\n",
    "        return None\n",
    "    dir = './data/masking_dicts'\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    dict_path = f'./data/masking_dicts/{country}_{direction}_{train_or_test}_calculated_dict.joblib'\n",
    "    images_paths_df = utils.get_available_data_dataframe()\n",
    "    images_paths_df = images_paths_df[images_paths_df['location'] == target_location]\n",
    "    images_paths_df = images_paths_df.reset_index(drop=True)\n",
    "    if len(images_paths_df) == 0:\n",
    "        print(f'No images for {target_location}')\n",
    "        return None\n",
    "    evalscripts = images_paths_df['evalscript'].values\n",
    "    indices = [i for i in range(len(evalscripts)) if evalscripts[i] in ['FCOVER', 'ALL']]\n",
    "    images_paths_df = images_paths_df.iloc[indices]\n",
    "    images_paths_df = images_paths_df.reset_index(drop=True)\n",
    "    \n",
    "    all_dates = images_paths_df['date'].unique()\n",
    "    dates_2019 = filter_date_by_year(all_dates, '2019')\n",
    "    dates_2020 = filter_date_by_year(all_dates, '2020')\n",
    "    monhts_2019 = ['07', '10', '12']\n",
    "    monhts_2020 = ['02', '04', '06']\n",
    "    dates = []\n",
    "    for month in monhts_2019:\n",
    "        dates += filter_date_by_month(dates_2019, month)\n",
    "    for month in monhts_2020:\n",
    "        dates += filter_date_by_month(dates_2020, month)\n",
    "    if dates is not None:\n",
    "        images_paths_df = images_paths_df[images_paths_df['date'].isin(dates)]\n",
    "        images_paths_df = images_paths_df.reset_index(drop=True)\n",
    "\n",
    "    if part2:\n",
    "        print(f'Getting masking_dict for {target_location} part 2: {len(images_paths_df)}')\n",
    "        print('Getting processed_src_gdf')\n",
    "        processed_src_gdf = get_processed_src_gdf(images_paths_df)\n",
    "        src_geom = processed_src_gdf.geometry.values\n",
    "        masking_dict = get_masking_dict_for_src_from_target(src_geom, target_gdf, dict_path)\n",
    "        processed_masked_src_gdf = get_processed_masked_src_gdf(processed_src_gdf, masking_dict)\n",
    "        joblib.dump(processed_masked_src_gdf, processed_gdf_path)\n",
    "        print(f'processed_masked_src_gdf: {len(processed_masked_src_gdf)} saved to {processed_gdf_path}')\n",
    "    else:\n",
    "        processed_src_gdf = get_processed_src_gdf_fcover(images_paths_df)\n",
    "        src_geom = processed_src_gdf.geometry.values\n",
    "        masking_dict = get_masking_dict_for_src_from_target(src_geom, target_gdf, dict_path)\n",
    "        return masking_dict\n",
    "\n",
    "\n",
    "def pre_prep_masking_jobs():\n",
    "    train_or_test_values = ['train', 'test']\n",
    "    country_values = ['Sudan', 'Iran']\n",
    "    direction_values = ['north_west', 'south_east', 'north_east', 'south_west']\n",
    "    for country in country_values:\n",
    "        print(f'country: {country}')\n",
    "        for train_or_test in train_or_test_values:\n",
    "            print(f'train_or_test: {train_or_test}')\n",
    "            if train_or_test == 'train':\n",
    "                data = utils.read_train_data()\n",
    "            elif train_or_test == 'test':\n",
    "                data = utils.read_test_data()\n",
    "            gdf, m, gdf_north_west, gdf_south_east, gdf_north_east, gdf_south_west = get_locations_and_map(data, country)\n",
    "            country_north_west = f'{country}_North_West_{train_or_test}'\n",
    "            country_south_east = f'{country}_South_East_{train_or_test}'\n",
    "            country_north_east = f'{country}_North_East_{train_or_test}'\n",
    "            country_south_west = f'{country}_South_West_{train_or_test}'\n",
    "            gdf_north_west = reszie_quarter_gdfs(gdf_north_west, country_north_west)\n",
    "            gdf_south_east = reszie_quarter_gdfs(gdf_south_east, country_south_east)\n",
    "            gdf_north_east = reszie_quarter_gdfs(gdf_north_east, country_north_east)\n",
    "            gdf_south_west = reszie_quarter_gdfs(gdf_south_west, country_south_west)\n",
    "            for direction in direction_values:\n",
    "                print(f'direction: {direction}')\n",
    "                masking_dict_job_args_path = f'./data/masking_jobs/{country}_{direction}_{train_or_test}_masking_dict_args.joblib'\n",
    "                if os.path.exists(masking_dict_job_args_path):\n",
    "                    continue\n",
    "                if direction == 'north_west':\n",
    "                    target_gdf = gdf_north_west.copy()\n",
    "                    target_location = country_north_west\n",
    "                elif direction == 'south_east':\n",
    "                    target_gdf = gdf_south_east.copy()\n",
    "                    target_location = country_south_east\n",
    "                elif direction == 'north_east':\n",
    "                    target_gdf = gdf_north_east.copy()\n",
    "                    target_location = country_north_east\n",
    "                elif direction == 'south_west':\n",
    "                    target_gdf = gdf_south_west.copy()\n",
    "                    target_location = country_south_west\n",
    "                masking_dict_args = {\n",
    "                    'target_gdf': target_gdf,\n",
    "                    'country': country,\n",
    "                    'direction': direction,\n",
    "                    'train_or_test': train_or_test,\n",
    "                    'target_location': target_location\n",
    "                }\n",
    "                joblib.dump(masking_dict_args, masking_dict_job_args_path)\n",
    "\n",
    "\n",
    "\n",
    "def main_parallel_data_processor(masking_dict_job_args_path):\n",
    "    masking_dict_args = joblib.load(masking_dict_job_args_path)\n",
    "    target_gdf = masking_dict_args['target_gdf']\n",
    "    country = masking_dict_args['country']\n",
    "    direction = masking_dict_args['direction']\n",
    "    train_or_test = masking_dict_args['train_or_test']\n",
    "    target_location = masking_dict_args['target_location']\n",
    "    masking_dict = creat_masking_dict(target_gdf, country, direction, train_or_test, target_location)\n",
    "    os.remove(masking_dict_job_args_path)\n",
    "    return masking_dict\n",
    "\n",
    "def main_parallel_data_processor_part_2(masking_dict_job_args_path):\n",
    "    masking_dict_args = joblib.load(masking_dict_job_args_path)\n",
    "    target_gdf = masking_dict_args['target_gdf']\n",
    "    country = masking_dict_args['country']\n",
    "    direction = masking_dict_args['direction']\n",
    "    train_or_test = masking_dict_args['train_or_test']\n",
    "    target_location = masking_dict_args['target_location']\n",
    "    masking_dict = creat_masking_dict(target_gdf, country, direction, train_or_test, target_location, part2=True)\n",
    "\n",
    "    os.remove(masking_dict_job_args_path)\n",
    "    return masking_dict\n",
    "\n",
    "def main():\n",
    "    # masking_dict_job_args_dir = './data/masking_jobs'\n",
    "    # masking_dict_job_args_files = os.listdir(masking_dict_job_args_dir)\n",
    "    # masking_dict_job_args_paths = [os.path.join(masking_dict_job_args_dir, masking_dict_job_args_file) for masking_dict_job_args_file in masking_dict_job_args_files]\n",
    "    # print(f'Number of masking_dict_job_args_paths: {len(masking_dict_job_args_paths)}')\n",
    "    # with Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "    #     pool.map(main_parallel_data_processor, masking_dict_job_args_paths)\n",
    "    # print('Done!')\n",
    "\n",
    "    ###Part 2\n",
    "    masking_dict_job_args_dir = './data/masking_jobs'\n",
    "    masking_dict_job_args_files = os.listdir(masking_dict_job_args_dir)\n",
    "    masking_dict_job_args_paths = [os.path.join(masking_dict_job_args_dir, masking_dict_job_args_file) for masking_dict_job_args_file in masking_dict_job_args_files]\n",
    "    print(f'Number of masking_dict_job_args_paths: {len(masking_dict_job_args_paths)}')\n",
    "    # with Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "    #     pool.map(main_parallel_data_processor_part_2, masking_dict_job_args_paths)\n",
    "    for i in tqdm(range(len(masking_dict_job_args_paths))):\n",
    "        main_parallel_data_processor_part_2(masking_dict_job_args_paths[i])\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "def generate_cloud_coverage_averages_through_time(location_name, gdf, year, dates):\n",
    "    saved_path = f'./avg_cloud_coverage/{location_name}_avg_cloud_coverage_{year}.joblib'\n",
    "    if os.path.exists(saved_path):\n",
    "        print('Loading Cloud Coverage Averages Through Time')\n",
    "        clp_averages = joblib.load(saved_path)\n",
    "    else:\n",
    "        print('Calculating Cloud Coverage Averages Through Time')\n",
    "        num_dates = len(dates)\n",
    "        clp_averages = []\n",
    "        for date in tqdm(dates):\n",
    "            clp, _ = utils.download_gdf_image_from_sentinelhub(gdf, date, 'CLP', location_name)\n",
    "            all_bands, _ = utils.download_gdf_image_from_sentinelhub(gdf, date, 'ALL', location_name)\n",
    "            fcover, _ = utils.download_gdf_image_from_sentinelhub(gdf, date, 'FCOVER', location_name)\n",
    "            clp_averages.append(np.mean(clp))\n",
    "        save_dir = './avg_cloud_coverage'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f'{location_name}_avg_cloud_coverage_{year}.joblib')\n",
    "        joblib.dump(clp_averages, save_path)\n",
    "    return clp_averages\n",
    "\n",
    "def plot_cloud_coverage_averages_through_time(location_name, clp_averages, year, dates):\n",
    "    fig, ax = plt.subplots(figsize=(50, 8))\n",
    "    ax.plot(dates, clp_averages)\n",
    "    ax.set_xticks(dates)\n",
    "    ax.set_xticklabels(dates, rotation=90)\n",
    "    ax.set_xlabel('Dates')\n",
    "    ax.set_ylabel('Cloud Coverage')\n",
    "    #increase font size in x and y ticks\n",
    "    ax.tick_params(axis='x', labelsize=25)\n",
    "    ax.tick_params(axis='y', labelsize=25)\n",
    "    #Add grid lines\n",
    "    ax.grid(True)\n",
    "    ax.set_title('Cloud Coverage Averages Through Time')\n",
    "    months = [date[5:7] for date in dates]\n",
    "    months_clp_averages = {}\n",
    "    for month in set(months):\n",
    "        months_clp_averages[month] = {\n",
    "            'dates': [],\n",
    "            'clp_averages': [],\n",
    "            'indices': [],\n",
    "        }\n",
    "    for i, month in enumerate(months):\n",
    "        months_clp_averages[month]['dates'].append(dates[i])\n",
    "        months_clp_averages[month]['clp_averages'].append(clp_averages[i])\n",
    "        months_clp_averages[month]['indices'].append(i)\n",
    "    for month in months_clp_averages:\n",
    "        months_clp_averages[month]['min_clp_average'] = min(months_clp_averages[month]['clp_averages'])\n",
    "        months_clp_averages[month]['min_clp_average_index'] = months_clp_averages[month]['clp_averages'].index(months_clp_averages[month]['min_clp_average'])\n",
    "        months_clp_averages[month]['min_clp_average_date'] = months_clp_averages[month]['dates'][months_clp_averages[month]['min_clp_average_index']]\n",
    "    min_clp_averages = []\n",
    "    min_clp_averages_dates = []\n",
    "    for month in months_clp_averages:\n",
    "        min_clp_averages.append(months_clp_averages[month]['min_clp_average'])\n",
    "        min_clp_averages_dates.append(months_clp_averages[month]['min_clp_average_date'])\n",
    "    ax.scatter(min_clp_averages_dates, min_clp_averages, marker='o', color='red', s=100)\n",
    "    for i, txt in enumerate(min_clp_averages):\n",
    "        txt = f'{txt:.2f}@{min_clp_averages_dates[i]}'\n",
    "        ax.annotate(txt, (min_clp_averages_dates[i], min_clp_averages[i]), fontsize=20)\n",
    "    fig_name = f'{location_name}_cloud_coverage_averages_through_time_{year}.pdf'\n",
    "    fig_dir = './avg_cloud_coverage'\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "    fig_path = os.path.join(fig_dir, fig_name)\n",
    "    fig.savefig(fig_path)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_or_test_values = ['train', 'test']\n",
    "country_values = ['Afghanistan']\n",
    "direction_values = ['north_west', 'south_east']\n",
    "for country in country_values:\n",
    "    print(f'country: {country}')\n",
    "    for train_or_test in train_or_test_values:\n",
    "        print(f'train_or_test: {train_or_test}')\n",
    "        if train_or_test == 'train':\n",
    "            data = utils.read_train_data()\n",
    "        elif train_or_test == 'test':\n",
    "            data = utils.read_test_data()\n",
    "        gdf, m, gdf_north_west, gdf_south_east, gdf_north_east, gdf_south_west = get_locations_and_map(data, country)\n",
    "        country_north_west = f'{country}_North_West_{train_or_test}'\n",
    "        country_south_east = f'{country}_South_East_{train_or_test}'\n",
    "        country_north_east = f'{country}_North_East_{train_or_test}'\n",
    "        country_south_west = f'{country}_South_West_{train_or_test}'\n",
    "        gdf_north_west = reszie_quarter_gdfs(gdf_north_west, country_north_west)\n",
    "        gdf_south_east = reszie_quarter_gdfs(gdf_south_east, country_south_east)\n",
    "        gdf_north_east = reszie_quarter_gdfs(gdf_north_east, country_north_east)\n",
    "        gdf_south_west = reszie_quarter_gdfs(gdf_south_west, country_south_west)\n",
    "        for direction in direction_values:\n",
    "            print(f'direction: {direction}')\n",
    "            if direction == 'north_west':\n",
    "                target_gdf = gdf_north_west.copy()\n",
    "                target_location = country_north_west\n",
    "            elif direction == 'south_east':\n",
    "                target_gdf = gdf_south_east.copy()\n",
    "                target_location = country_south_east\n",
    "            elif direction == 'north_east':\n",
    "                target_gdf = gdf_north_east.copy()\n",
    "                target_location = country_north_east\n",
    "            elif direction == 'south_west':\n",
    "                target_gdf = gdf_south_west.copy()\n",
    "                target_location = country_south_west\n",
    "            year = '2022'\n",
    "            dates =[\n",
    "                '2022-05-28',\n",
    "                '2022-05-23',\n",
    "                '2022-05-18',\n",
    "                '2022-05-13',\n",
    "                '2022-05-08',\n",
    "                '2022-05-03',\n",
    "                '2022-04-28',\n",
    "                '2022-04-23',\n",
    "                '2022-04-18',\n",
    "                '2022-04-13',\n",
    "                '2022-04-08',\n",
    "                '2022-04-03',\n",
    "                '2022-03-29',\n",
    "                '2022-03-24',\n",
    "                '2022-03-19',\n",
    "                '2022-03-14',\n",
    "                '2022-03-09',\n",
    "                '2022-03-04',\n",
    "                '2022-02-27',\n",
    "                '2022-02-22',\n",
    "                '2022-02-17',\n",
    "                '2022-02-12',\n",
    "                '2022-02-07',\n",
    "                '2022-02-02',\n",
    "                '2022-01-28',\n",
    "                '2022-01-23',\n",
    "                '2022-01-18',\n",
    "                '2022-01-13',\n",
    "                '2022-01-08',\n",
    "                '2022-01-03',\n",
    "            ]\n",
    "            clp_avgs = generate_cloud_coverage_averages_through_time(target_location, target_gdf, year, dates)\n",
    "            plot_cloud_coverage_averages_through_time(target_location, clp_avgs, year, dates)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
